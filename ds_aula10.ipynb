{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMO6sEzqIWBOvJfMygg9MRv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Métricas de Avaliação de Modelos:\n","\n","      MSE = Erro Quadrático Médio (Mean Squared Error)\n","            1. Calcula a média dos quadrados das diferenças entre os valores reais e previstos.\n","            2. Quanto menor o MSE, melhor o modelo. Ou seja, previsões mais próximas da realidade.\n","            3. É sensível a outliers (valores discrepantes), pois eleva ao quadrado as diferenças.\n","            4. (12−10)^2=4 ou (10−50)²=1600\n","            5. **Exemplo de utilização**: Avaliar a performance de um modelo de regressão que prevê o preço de imóveis, onde grandes discrepâncias nos preços (outliers) podem ser mais prejudiciais para o desempenho do modelo.\n","\n","      RMSE = Raiz do Erro Quadrático Médio (Root Mean Squared Error)\n","            1. É a raiz quadrada do MSE.\n","            2. Tem a mesma unidade de medida dos dados originais, facilitando a interpretação.\n","            3. Assim como o MSE, é sensível a outliers.\n","            4. √4=2 ou √1600=40\n","            5. **Exemplo de utilização**: Utilizar para medir a precisão de um modelo de previsão de demanda de vendas em uma empresa, onde a unidade de medida (quantidade de produtos) deve ser interpretada diretamente.\n","\n","      MAE = Erro Médio Absoluto (Mean Absolute Error)\n","            1. Calcula a média dos valores absolutos das diferenças entre os valores reais e previstos.\n","            2. Menos sensível a outliers em comparação com o MSE.\n","            3. A interpretação é direta: quanto menor o MAE, melhor o modelo.\n","            4. |12−10|=2 ou |50−10|=40\n","            5. **Exemplo de utilização**: Avaliar um modelo de previsão de temperatura média diária, onde as pequenas variações nas previsões são mais relevantes do que grandes erros ocasionais.\n","\n","      MAPE = Erro Médio Percentual Absoluto (Mean Absolute Percentage Error)\n","            1. Calcula o erro médio em termos percentuais, expressando a diferença entre os valores reais e previstos como uma porcentagem.\n","            2. Fácil de interpretar e comparar entre diferentes modelos.\n","            3. Não funciona bem quando os valores reais estão próximos de zero, pois o erro percentual pode se tornar infinito.\n","            4. ((12−10)/10)×100=20% ou ((50−10)/10)×100=400%\n","            5. **Exemplo de utilização**: Comparar modelos de previsão de vendas de um produto, já que o MAPE fornece uma medida intuitiva de erro percentual, facilitando a comparação entre diferentes regiões ou períodos de tempo.\n","\n","      R² = Coeficiente de Determinação (R Squared)\n","            1. Mede a proporção da variabilidade dos dados que é explicada pelo modelo.\n","            2. Varia de 0 a 1, sendo 1 um modelo perfeito e 0 um modelo sem poder explicativo.\n","            3. Pode ser negativo se o modelo for pior que a simples média dos dados.\n","            4. R² = 0.8 significa que 80% da variabilidade é explicada pelo modelo.\n","            5. **Exemplo de utilização**: Avaliar a qualidade de um modelo de regressão linear que tenta prever o valor de ações financeiras, verificando quanto da variação nos preços é explicada pelo modelo.\n","\n","      Adjusted R² = Coeficiente de Determinação Ajustado (Adjusted R Squared)\n","            1. Versão ajustada do R², levando em conta o número de variáveis independentes no modelo.\n","            2. Útil para modelos com múltiplas variáveis, já que penaliza a inclusão de variáveis irrelevantes.\n","            3. Permite a comparação de modelos com diferentes números de variáveis.\n","            4. O valor ajustado pode ser menor que o R², especialmente quando o modelo possui variáveis desnecessárias.\n","            5. **Exemplo de utilização**: Comparar modelos de previsão de vendas com diferentes números de variáveis explicativas, como preço, localização e características do produto.\n","\n","      AIC = Critério de Informação de Akaike (Akaike Information Criterion)\n","            1. Mede a qualidade do modelo, penalizando modelos mais complexos (com mais parâmetros).\n","            2. Quanto menor o AIC, melhor o modelo, balanceando a **qualidade do ajuste** e a **complexidade do modelo**.\n","            3. Útil para **seleção de modelos**, ajudando a escolher entre modelos concorrentes.\n","            4. AIC = -2 log(verossimilhança) + 2k, onde \"k\" é o número de parâmetros no modelo.\n","            5. **Exemplo de utilização**: Comparar diferentes modelos de previsão de tráfego em uma cidade, onde modelos mais simples são preferíveis, a menos que a complexidade extra traga uma melhoria substancial no desempenho.\n","\n","      BIC = Critério de Informação Bayesiano (Bayesian Information Criterion)\n","            1. Similar ao AIC, mas com penalização maior para o número de parâmetros no modelo.\n","            2. Considera a probabilidade do modelo, levando em conta tanto a **verossimilhança** quanto a **complexidade**.\n","            3. Quanto menor o BIC, melhor o modelo.\n","            4. BIC = -2 log(verossimilhança) + k log(n), onde \"n\" é o número de observações.\n","            5. **Exemplo de utilização**: Utilizar para selecionar o melhor modelo para prever o risco de crédito de clientes em uma instituição financeira, onde a simplicidade do modelo é preferida, mas sem sacrificar a precisão."],"metadata":{"id":"hmN0jU16RWgT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHyADM12JGF7"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.linear_model import LinearRegression"]},{"cell_type":"code","source":["# Valores reais\n","true = [3,-0.5, 2, 7]\n","\n","# Valores preditos\n","pred = [2.5, 0.0, 2, 8]\n","\n","# Calculando o MSE ()\n","mse = mean_squared_error(true, pred)\n","print(mse)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CO9_t6kiLK7X","executionInfo":{"status":"ok","timestamp":1758583526451,"user_tz":180,"elapsed":24,"user":{"displayName":"Daniel Alves Pinho","userId":"11550645673798998657"}},"outputId":"efa1b93a-6c9b-484c-db5e-8c142c4e3d00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["72.5\n"]}]},{"cell_type":"code","source":["# MSE de Treino x MSE de Teste\n","'''\n","De Treino = calculado usando dados que foram usados pré estabelecidos\n","De Teste = calculado usando dados nunca antes vistos pelo modelo\n","'''\n","\n","# Overfitting\n","'''\n","Ocorre quando o modelo se ajusta aos dados de treino bem, mas não tem um resultado tão bom nos dados de teste.\n","Importante que seja baixo para melhor desempenho durante os testes.\n","'''\n","\n","# Underfitting\n","'''\n","Ocorre quando o modelo NÃO consegue se ajustar aos dados de treino e NEM aos dados de teste. Ou modelo é complexo, ou há poucos dados de treino.\n","'''\n","\n","\n"],"metadata":{"id":"eLM3nY7rP6au"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["            #### EXEMPLO DE OVERFITTING\n","import random\n","\n","\n","# Dados de treino\n","X_train = [[0,0],[2,2], [1,2], [2,3]]     # dados de entrada pro treino\n","y_train = [0,1,2,3]                       # saída almejada (target)\n","\n","# Dados de teste\n","X_test = [[round(random.uniform(1.0, 4.0), 2), round(random.uniform(1.0, 4.0), 2)] for _ in range(4)]   #  novo valor para ser previsto\n","y_test = [round(random.uniform(1.0, 4.0), 2) for _ in range(4)]                                         #  valor esperado para este ponto\n","\n","print(\"X_test:\", X_test)\n","print(\"y_test:\", y_test)\n","\n","# Modelo de Árvore de Decisão\n","tree = DecisionTreeRegressor()            # modelo de árvore de decisão para regressão\n","\n","#Treinamento do modelo\n","tree.fit(X_train, y_train)                # aprendizado com dados de treino\n","\n","# Predição\n","y_pred_train = tree.predict(X_train)      # previsão do modelo com dados do treino (já conhecido)\n","y_pred_test = tree.predict(X_test)        # previsão do modelo com teste (desconhecido)\n","\n","print(f'Predição de Treino: {y_pred_train}')\n","print(f'Predição de Teste: {y_pred_test}')\n","\n","# MSE de treino\n","mse_train = mean_squared_error(y_train, y_pred_train)           # MSE entre treino X treino\n","mse_test = mean_squared_error(y_test, y_pred_test)              # MSE entre treino X teste (confere se foi decoreba ou assertivo)\n","\n","print(f'MSE de treino: {mse_train}')\n","print(f'MSE de teste: {mse_test}')\n","\n"],"metadata":{"id":"jOSIsN8lTRNB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","# Dados de treino\n","X_train = [[0,0],[2,2], [1,2], [2,3]]\n","y_train = [0,1,2,3]\n","\n","# Treinar o modelo\n","tree = DecisionTreeRegressor()\n","tree.fit(X_train, y_train)\n","\n","# Pontos para previsão e avaliação\n","x_valores = [[x, x] for x in range(0, 3)]\n","\n","# Valores verdadeiros (exemplo simples: soma das features)\n","y_true = [sum(x) for x in x_valores]  # [0, 2, 4]\n","\n","# Previsão do modelo\n","y_valores = tree.predict(x_valores)\n","\n","# Calcular MSE\n","mse = mean_squared_error(y_true, y_valores)\n","print(f'MSE: {mse}')\n","\n","# Plotagem\n","plt.scatter([0, 2], [0, 2], color='blue', label='Treino')\n","plt.scatter(1, 1, color='green', label='Teste', marker='x', s=100)\n","plt.plot([x[0] for x in x_valores], y_valores, color='red', label='Modelo')\n","\n","plt.legend()\n","plt.title(\"Exemplo de Overfitting com Árvore de Decisão\")\n","plt.xlabel('Feature (X, input)')\n","plt.ylabel('Target (y, output)')\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"zo7e0OgkcXC6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["        #### EXEMPLO VISUAL DE OVERFITTING\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","# Dados de treino\n","X_train = [[0, 0], [2, 2]]\n","y_train = [0, 2]\n","\n","# Dados de teste\n","X_test = [[1, 1]]\n","\n","# Modelo de Árvore de Decisão\n","tree_model = DecisionTreeRegressor()\n","\n","# Treinamento do modelo\n","tree_model.fit(X_train, y_train)\n","\n","# Predição\n","y_pred_train = tree_model.predict(X_train)\n","y_pred_test = tree_model.predict(X_test)\n","\n","# MSE de treino\n","mse_train = mean_squared_error(y_train, y_pred_train)\n","mse_test = mean_squared_error([1], y_pred_test)\n","\n","print('MSE de treino:', mse_train)\n","print('MSE de teste:', mse_test)\n","\n","# Visualização da Árvore de Decisão\n","plt.figure(figsize=(10, 6))\n","\n","# Plotando os pontos de treino\n","plt.scatter([point[0] for point in X_train], y_train, color='blue', label='Pontos de Treinamento')\n","\n","# Plotando a predição do modelo nos pontos de treino\n","plt.scatter([point[0] for point in X_train], y_pred_train, color='red', marker='x', label='Predições de Treinamento')\n","\n","# Plotando os pontos de teste\n","plt.scatter([point[0] for point in X_test], [1], color='green', marker='s', label='Pontos de Teste')\n","\n","# Ajuste da linha para o gráfico (para fins de visualização, estamos projetando uma linha simples)\n","# Criar uma grade de pontos para o gráfico com 2 características\n","X_range = np.linspace(-1, 3, 100).reshape(-1, 1)\n","X_range_full = np.column_stack([X_range, X_range])  # Criando um grid de 2D, pois o modelo foi treinado com 2 características\n","\n","# Predição para o grid 2D\n","y_range = tree_model.predict(X_range_full)\n","\n","# Linha de decisão do modelo\n","plt.plot(X_range, y_range, color='black', linestyle='--', label='Linha de Decisão')\n","\n","plt.title('Árvore de Decisão - Previsões de Treinamento e Teste')\n","plt.xlabel('Feature (X, input)')\n","plt.ylabel('Target (y, output)')\n","plt.legend(loc='upper left')\n","\n","# Exibir a árvore\n","plt.show()\n","\n","# Exibir MSE\n","print(f\"MSE de treino: {mse_train}\")\n","print(f\"MSE de teste: {mse_test}\")\n"],"metadata":{"collapsed":true,"id":"XQjqeuLXVRUt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["      #### EXEMPLO DE UNDERFITTING\n","\n","# Dados não-lineares\n","import numpy as np\n","\n","X_train = np.array([[0], [1], [2], [3], [4], [5]])\n","y_train = np.array([0, 1, 4, 9, 16, 25])  # y = x²\n","\n","# Modelo de Regressão Linear (vai tentar fazer uma reta)\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","y_pred_train = model.predict(X_train)\n","train_error = mean_squared_error(y_train, y_pred_train)\n","\n","print(\"MSE de Treino\", train_error)\n"],"metadata":{"id":"CIgAFFuDT4mr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758586653622,"user_tz":180,"elapsed":50,"user":{"displayName":"Daniel Alves Pinho","userId":"11550645673798998657"}},"outputId":"e69e4dbb-9bc6-4888-d877-08d3ff768a84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Erro de treino: 6.222222222222224\n"]}]},{"cell_type":"code","source":["      #### EXEMPLO VISUAL DE UNDERFITTING\n","\n","\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","# Dados quadráticos (não-lineares)\n","X_train = np.array([[0], [1], [2], [3], [4], [5]])\n","y_train = np.array([0, 1, 4, 9, 16, 25])  # y = x²\n","\n","# Treinando um modelo de regressão linear\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# Fazendo predições\n","y_pred_train = model.predict(X_train)\n","y_pred_test = model.predict([[6]])  # Predição para um novo ponto\n","\n","print (f'Predição do novo ponto {y_pred_test}')\n","\n","# Erro de treino\n","train_error = mean_squared_error(y_train, y_pred_train)\n","print(\"Erro de treino:\", train_error)\n","\n","# Visualização\n","plt.scatter(X_train, y_train, color='blue', label='Dados reais')\n","plt.plot(X_train, y_pred_train, color='red', label='Regressão Linear')\n","plt.title(\"Exemplo de Underfitting\")\n","plt.xlabel(\"X, Feature\")\n","plt.ylabel(\"y, Target\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"XUk8tLK5dVKh"},"execution_count":null,"outputs":[]}]}